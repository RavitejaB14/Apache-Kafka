Kafka Producer Configs:

1. Bootstrap Servers: Used to connect to Kafka Cluster.

A list of host/port pairs to use for establishing the initial connection to the Kafka cluster. 
The client will make use of all servers irrespective of which servers are specified here for bootstrapping—this list 
only impacts the initial hosts used to discover the full set of servers. 
This list should be in the form host1:port1,host2:port2,.... 
Since these servers are just used for the initial connection to discover the full cluster membership 
(which may change dynamically), this list need not contain the full set of servers 
(you may want more than one, though, in case a server is down).

Type:	list
Default:	""
Valid Values:	non-null string
Importance:	high

2. ClientID: Used to trace the requests. Mainly used for debugging.

An id string to pass to the server when making requests. 
The purpose of this is to be able to track the source of requests beyond just ip/port by allowing a logical application name 
to be included in server-side request logging.

Type:	string
Default:	""
Valid Values:	
Importance:	medium



3. Key Serializer: Serialization is the process of converting an object into stream of bytes.

Why serialization:

-> To persist the object.
-> To Transmit an object across the network.

Every message in kafka has a key and value associated with it.

Serializer class for key that implements the org.apache.kafka.common.serialization.Serializer interface.
Default serialization is byte array serialization.


Type:	class
Default:	
Valid Values:	
Importance:	high

4: Value Serializer:

Serializer class for value that implements the org.apache.kafka.common.serialization.Serializer interface.

Type:	class
Default:	
Valid Values:	
Importance:	high

5. Connections.max.idle.ms: Whenever producer is connecting to Kafka cluster. So till what time the connection needs to be closed is decided by this property.

Default is 540000 ~ 9min, If producer did'nt send any message under this time, It will close the connection.

Close idle connections after the number of milliseconds specified by this config.

Type:	long
Default:	540000
Valid Values:	
Importance:	medium


6. Acks: When producer send a records, it waits for the acknowledgement from the cluster.

The number of acknowledgments the producer requires the leader to have received before considering a request complete. This controls the durability of records that are sent. The following settings are allowed:

acks=0: If set to zero then the producer will not wait for any acknowledgment from the server at all. 
The record will be immediately added to the socket buffer and considered sent.
 No guarantee can be made that the server has received the record in this case, and the retries configuration 
 will not take effect (as the client won't generally know of any failures). 
 The offset given back for each record will always be set to -1.

acks=1: This will mean the leader will write the record to its local log but will respond without awaiting 
full acknowledgement from all followers. 
In this case should the leader fail immediately after acknowledging the record but before the followers have replicated it 
then the record will be lost.

acks=all: This means the leader will wait for the full set of in-sync replicas to acknowledge the record. 
This guarantees that the record will not be lost as long as at least one in-sync replica remains alive.
 This is the strongest available guarantee. This is equivalent to the acks=-1 setting.

Type:	string
Default:	1
Valid Values:	[all, -1, 0, 1]
Importance:	high

7. compression.type: Used to compress the messages. Default value is None

The compression type for all data generated by the producer. The default is none (i.e. no compression). 
Valid values are none, gzip, snappy, lz4, or zstd. 
Compression is of full batches of data, so the efficacy of batching will also impact 
the compression ratio (more batching means better compression).

Type:	string
Default:	none
Valid Values:	
Importance:	high

8. Batch.size:   

The producer will attempt to batch records together into fewer requests whenever multiple records 
are being sent to the same partition. This helps performance on both the client and the server. 
This configuration controls the default batch size in bytes.

No attempt will be made to batch records larger than this size.

Requests sent to brokers will contain multiple batches, one for each partition with data available to be sent.

A small batch size will make batching less common and may reduce throughput 
(a batch size of zero will disable batching entirely). A very large batch size may use memory a bit more wastefully 
as we will always allocate a buffer of the specified batch size in anticipation of additional records.

Type:	int
Default:	16384
Valid Values:	[0,...]
Importance:	medium


9. buffer.memory:

The total bytes of memory[RAM] the producer can use to buffer records waiting to be sent to the server. 
If records are sent faster than they can be delivered to the server the producer will block for max.block.ms 
after which it will throw an exception.

This setting should correspond roughly to the total memory the producer will use, 
but is not a hard bound since not all memory the producer uses is used for buffering. 
Some additional memory will be used for compression (if compression is enabled) as well as for maintaining 
in-flight requests.

Type:	long
Default:	33554432
Valid Values:	[0,...]
Importance:	high


10. linger.ms: 

The producer groups together any records that arrive in between request transmissions into a single batched request. 
Normally this occurs only under load when records arrive faster than they can be sent out. 
However in some circumstances the client may want to reduce the number of requests even under moderate load. 
This setting accomplishes this by adding a small amount of artificial delay—that is, rather than immediately 
sending out a record the producer will wait for up to the given delay to allow other records to be sent 
so that the sends can be batched together. This can be thought of as analogous to Nagle's algorithm in TCP. 
This setting gives the upper bound on the delay for batching: once we get batch.size worth of records for a partition 
it will be sent immediately regardless of this setting, however if we have fewer than this many bytes accumulated for this partition 
we will 'linger' for the specified time waiting for more records to show up. 
This setting defaults to 0 (i.e. no delay). Setting linger.ms=5, 
for example, would have the effect of reducing the number of requests sent but would add up to 5ms of latency
 to records sent in the absence of load.

Type:	long
Default:	0
Valid Values:	[0,...]
Importance:	medium


11. max.requests.size: batch.size should be less than this property.

The maximum size of a request in bytes. This setting will limit the number of record batches the producer will send 
in a single request to avoid sending huge requests. 
This is also effectively a cap on the maximum uncompressed record batch size. 
Note that the server has its own cap on the record batch size (after compression if compression is enabled) 
which may be different from this.

Type:	int
Default:	1048576
Valid Values:	[0,...]
Importance:	medium

Note: how to pass these configs:

-> bin/kafka-console-producer.sh --bootstrap-server localhost:9092 --topic test --producer.config config/producer.properties


12: Idempotent Producer: enable.Idempotence

When set to 'true', the producer will ensure that exactly one copy of each message is written in the stream. 
If 'false', producer retries due to broker failures, etc., may write duplicates of the retried message in the stream.
 Note that enabling idempotence requires max.in.flight.requests.per.connection to be less than or equal to 5, 
 retries to be greater than 0 and acks must be 'all'. If these values are not explicitly set by the user, 
 suitable values will be chosen. If incompatible values are set, a ConfigException will be thrown.

Type:	boolean
Default:	false
Valid Values:	
Importance:	low

