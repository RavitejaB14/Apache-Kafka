
** Kafka Storage Architecture:

1. Kafka Organizes the messages in Topics.
2. Broker Creates a log file for each topic to store these messages.
3. These log files are partitioned -> replicated -> Segmented.

For Example: Refer - Examples (01-storage-demo -> it creates a zookeeper, three Kafka Brokers, creates a kafka topic)

Topic Partition replicas are classified into two catagories:

1. Leader Partitions
2. Follower Partitions

In the above example , we specified the number of partitions as 5, Kafka will create 5 Directories. These 5 Directories are called as Leader Partitions
Since the replication factor is 3 , One is already created as Leader, It will create another 2 directories as Followers.
Note: Follower is the duplicate copy of Leader.

To know which one are leaders and which one are follower, we use Kafka Describe command:

Topic: invoice  TopicId: Jf2HNDMNQf6clyF5viFs2w PartitionCount: 5       ReplicationFactor: 3    Configs: segment.bytes=1000000
        Topic: invoice  Partition: 0    Leader: 2       Replicas: 2,1,0 Isr: 2,1,0
        Topic: invoice  Partition: 1    Leader: 0       Replicas: 0,2,1 Isr: 0,2,1
        Topic: invoice  Partition: 2    Leader: 1       Replicas: 1,0,2 Isr: 1,0,2
        Topic: invoice  Partition: 3    Leader: 2       Replicas: 2,0,1 Isr: 2,0,1
        Topic: invoice  Partition: 4    Leader: 0       Replicas: 0,1,2 Isr: 0,1,2

Kafka Log Segment:

The Messages are stored within the directories in the log files. Instead of creating one large file in the directory, Kafka creates several smaller files
Which means the kafka log files is split into smaller files called segments

The default maximum size of segment is either 1 GB of data or a week of data.
Here I configured Max segment size as 1MB.



Kafka Message Offsets:

Each Message in the partition is uniquely Identified by a 64 bit Integer Offset.
Each Kafka Message within a single partition is uniquely Identified by the offset.

For example, the offset in the first message in the partitions would be 0000, the offset for the Second message would be 0001.

Let's consider the offset of the last message in the first segment is 30652,  Assume the maximum segment size is reached.
So Kafka should close this segment and create a new segment for the next message. So the offset of the first message in the Second segment would be 30653.

If you want to locate a specific message, we should know three things.

1. Topic name
2. Partition number
3. Offset number

Kafka Message Index:

Consider we have stream processing Application, the application connects to broker and asks for the messages that is starting from offset 0000


BROKER --> request-> 0
BROKER --> received -> 0-9
BROKER --> Process --> 0-9

BROKER --> request-> from 10
BROKER --> received -> 10-24
BROKER --> Process --> 10-24


To Help brokers rapidly to find the message for a given offset, Kafka maintains an index of offsets. The Index files are also segmented for easy management.
They are also stored in the partition directory along with the log file segments.

time index files: Kafka allows consumers to start fetching messages based on the offset number.
In some use cases, you might want to seek messages based on timestamp. these requierements are as straightforwardas you want to read
all the events that are created after a specific timestamp.

To support such needs. Kafka also maintains the timestamp for each message builds a timeindex to quickly seek the first message that arrived after the given timestamp.
The time index is like the offset index, and it is also segmented and stored in the parititon directory




