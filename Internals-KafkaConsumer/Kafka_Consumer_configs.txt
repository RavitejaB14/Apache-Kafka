Kafka consumer Configs:

1. bootstrap.server:

2. client.id: 

An id string to pass to the server when making requests. 
The purpose of this is to be able to track the source of requests beyond just ip/port by allowing a 
logical application name to be included in server-side request logging.

Type:	string
Default:	""
Valid Values:	
Importance:	medium


3. key.deserializer: 

Deserializer class for key that implements the org.apache.kafka.common.serialization.Deserializer interface.

Type:	class
Default:	
Valid Values:	
Importance:	high

4. value.deserializer:

Deserializer class for value that implements the org.apache.kafka.common.serialization.Deserializer interface.

Type:	class
Default:	
Valid Values:	
Importance:	high


5. group.id:

A unique string that identifies the consumer group this consumer belongs to. This property is required if the consumer uses either the group management functionality by using subscribe(topic) or the Kafka-based offset management strategy.

Type:	string
Default:	null
Valid Values:	
Importance:	high

6. fetch.min.bytes:

The minimum amount of data the server should return for a fetch request. 
If insufficient data is available the request will wait for that much data to accumulate before answering the request. 
The default setting of 1 byte means that fetch requests are answered as soon as a single byte of data is available or 
the fetch request times out waiting for data to arrive. Setting this to something greater than 1 will cause the server
to wait for larger amounts of data to accumulate which can improve server throughput a bit at the cost of some 
additional latency.

Type:	int
Default:	1
Valid Values:	[0,...]
Importance:	high


7. heartbeat.interval.ms: consumer will send periodic heartbeaT to group coordinator that this consumer is alive.
This should be less than the "session.timeout.ms".

The expected time between heartbeats to the consumer coordinator when using Kafka's group management facilities. 
Heartbeats are used to ensure that the consumer's session stays active and to facilitate rebalancing
 when new consumers join or leave the group. The value must be set lower than session.timeout.ms, 
 but typically should be set no higher than 1/3 of that value. It can be adjusted even lower to control the 
 expected time for normal rebalances.

Type:	int
Default:	3000 (3sec)
Valid Values:	
Importance:	high


8. session.timeout.ms: default is 10sec which means, if consumer won't sent the heartbeat until 10sec to group coordinator, 
that consumer is considered as dead. and it will be removed from the consumer group.


The timeout used to detect client failures when using Kafka's group management facility. 
The client sends periodic heartbeats to indicate its liveness to the broker. 
If no heartbeats are received by the broker before the expiration of this session timeout, 
then the broker will remove this client from the group and initiate a rebalance. 
Note that the value must be in the allowable range as configured in the broker configuration by group.min.session.timeout.ms and group.max.session.timeout.ms.

Type:	int
Default:	10000
Valid Values:	
Importance:	high


9. max.partition.fetch.bytes:

The maximum amount of data per-partition the server will return. Records are fetched in batches by the consumer. 
If the first record batch in the first non-empty partition of the fetch is larger than this limit, 
the batch will still be returned to ensure that the consumer can make progress. 
The maximum record batch size accepted by the broker is defined via message.max.bytes (broker config) 
or max.message.bytes (topic config). See fetch.max.bytes for limiting the consumer request size.

Type:	int
Default:	1048576
Valid Values:	[0,...]
Importance:	high


10. fetch.max.bytes:

The maximum amount of data the server should return for a fetch request. 
Records are fetched in batches by the consumer, and if the first record batch in the first non-empty partition of the 
fetch is larger than this value, the record batch will still be returned to ensure that the consumer can make progress. 
As such, this is not a absolute maximum. The maximum record batch size accepted by the broker is defined via 
message.max.bytes (broker config) or max.message.bytes (topic config). Note that the consumer performs multiple fetches
 in parallel.

Type:	int
Default:	52428800
Valid Values:	[0,...]
Importance:	medium
